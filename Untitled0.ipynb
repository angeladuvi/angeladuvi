{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/angeladuvi/angeladuvi/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8bgPBm_nRoB"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from deepface import DeepFace\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "from datetime import date\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del archivo de video (asegúrate de que la ruta sea correcta)\n",
        "video_path = \"carmen1.mp4\"\n",
        "\n",
        "# Pedir nombre, edad y género al inicio\n",
        "nombre = input(\"Introduce tu nombre: \")\n",
        "edad = input(\"Introduce tu edad: \")\n",
        "genero = input(\"Introduce tu género (Hombre/Mujer): \")\n",
        "\n",
        "# Inicializar detección de rostros\n",
        "mp_face_detection = mp.solutions.face_detection\n",
        "face_detection = mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5)\n",
        "\n",
        "# Inicializar diccionario para almacenar emociones\n",
        "emociones = {\n",
        "    'angry': 0,\n",
        "    'disgust': 0,\n",
        "    'fear': 0,\n",
        "    'happy': 0,\n",
        "    'sad': 0,\n",
        "    'surprise': 0,\n",
        "    'neutral': 0\n",
        "}\n",
        "\n",
        "total_frames = 0\n",
        "\n",
        "# Captura de video\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "if not cap.isOpened():\n",
        "    print(\"Error al abrir el video\")\n",
        "    exit()\n",
        "\n",
        "# Obtener el número total de frames\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# Iniciar procesamiento de video con barra de progreso\n",
        "with tqdm(total=total_frames, desc=\"Procesando video\") as pbar:\n",
        "    while(True):\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Convertir a RGB\n",
        "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Detectar rostros\n",
        "        results = face_detection.process(rgb)\n",
        "\n",
        "        if results.detections:\n",
        "            for detection in results.detections:\n",
        "                try:\n",
        "                    # Analizar emociones\n",
        "                    analyze = DeepFace.analyze(rgb, actions=['emotion'], enforce_detection=False)\n",
        "\n",
        "                    # Manejar el caso en que `DeepFace.analyze` devuelve una lista\n",
        "                    if isinstance(analyze, list):\n",
        "                        analyze = analyze[0]\n",
        "\n",
        "                    # Contar emociones\n",
        "                    emocion = analyze['dominant_emotion']\n",
        "                    emociones[emocion] += 1\n",
        "                except Exception as e:\n",
        "                    print(f\"Error al analizar el rostro: {e}\")\n",
        "\n",
        "        pbar.update(1)\n",
        "\n",
        "# Liberar recursos\n",
        "cap.release()\n",
        "\n",
        "# Calcular porcentajes\n",
        "if total_frames > 0:\n",
        "    porcentajes = {emocion: (conteo / total_frames) * 100 for emocion, conteo in emociones.items()}\n",
        "\n",
        "    # Mostrar resultados\n",
        "    print(\"\\nResultados del análisis:\")\n",
        "    print(f\"Nombre: {nombre}, Edad: {edad}, Género: {genero}\")\n",
        "    print(f\"Fecha del análisis: {date.today()}\")\n",
        "    for emocion, porcentaje in porcentajes.items():\n",
        "        print(f\"{emocion}: {porcentaje:.2f}%\")\n",
        "\n",
        "    # Verificar si la suma de porcentajes es 100\n",
        "    suma_porcentajes = sum(porcentajes.values())\n",
        "    print(f\"Suma total: {suma_porcentajes:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38ydSowSuE-v",
        "outputId": "5b6ebad5-a9e8-4e89-936b-fc6e42e62314"
      },
      "execution_count": 1,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Introduce tu nombre: \n",
            "Introduce tu edad: \n",
            "Introduce tu género (Hombre/Mujer): dev\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcesando video:   0%|          | 0/210 [00:00<?, ?it/s]Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/facial_expression_model_weights.h5\n",
            "To: /root/.deepface/weights/facial_expression_model_weights.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24-10-03 00:05:04 - facial_expression_model_weights.h5 will be downloaded...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 5.98M/5.98M [00:00<00:00, 237MB/s]\n",
            "Procesando video: 100%|██████████| 210/210 [02:08<00:00,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Resultados del análisis:\n",
            "Nombre: , Edad: , Género: dev\n",
            "Fecha del análisis: 2024-10-03\n",
            "angry: 0.00%\n",
            "disgust: 0.00%\n",
            "fear: 8.10%\n",
            "happy: 10.95%\n",
            "sad: 9.52%\n",
            "surprise: 0.00%\n",
            "neutral: 71.43%\n",
            "Suma total: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from deepface import DeepFace\n",
        "import cv2\n",
        "import mediapipe as mp #This module is now installed and can be imported\n",
        "from datetime import date\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del archivo de video (asegúrate de que la ruta sea correcta)\n",
        "video_path = \"carmen1.mp4\"\n",
        "\n",
        "# Pedir nombre, edad y género al inicio\n",
        "nombre = input(\"Introduce tu nombre: \")\n",
        "edad = input(\"Introduce tu edad: \")\n",
        "genero = input(\"Introduce tu género (Hombre/Mujer): \")\n",
        "\n",
        "# Inicializar detección de rostros\n",
        "mp_face_detection = mp.solutions.face_detection\n",
        "face_detection = mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5)\n",
        "\n",
        "# Inicializar diccionario para almacenar emociones\n",
        "emociones = {\n",
        "    'angry': 0,\n",
        "    'disgust': 0,\n",
        "    'fear': 0,\n",
        "    'happy': 0,\n",
        "    'sad': 0,\n",
        "    'surprise': 0,\n",
        "    'neutral': 0\n",
        "}\n",
        "\n",
        "total_frames = 0\n",
        "\n",
        "# Captura de video\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "if not cap.isOpened():\n",
        "    print(\"Error al abrir el video\")\n",
        "    exit()\n",
        "\n",
        "# Obtener el número total de frames\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# Iniciar procesamiento de video con barra de progreso\n",
        "with tqdm(total=total_frames, desc=\"Procesando video\") as pbar:\n",
        "    while(True):\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Convertir a RGB\n",
        "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Detectar rostros\n",
        "        results = face_detection.process(rgb)\n",
        "\n",
        "        if results.detections:\n",
        "            for detection in results.detections:\n",
        "                try:\n",
        "                    # Analizar emociones\n",
        "                    analyze = DeepFace.analyze(rgb, actions=['emotion'], enforce_detection=False)\n",
        "\n",
        "                    # Manejar el caso en que `DeepFace.analyze` devuelve una lista\n",
        "                    if isinstance(analyze, list):\n",
        "                        analyze = analyze[0]\n",
        "\n",
        "                    # Contar emociones\n",
        "                    emocion = analyze['dominant_emotion']\n",
        "                    emociones[emocion] += 1\n",
        "                except Exception as e:\n",
        "                    print(f\"Error al analizar el rostro: {e}\")\n",
        "\n",
        "        pbar.update(1)\n",
        "\n",
        "# Liberar recursos\n",
        "cap.release()\n",
        "\n",
        "# Calcular porcentajes\n",
        "if total_frames > 0:\n",
        "    porcentajes = {emocion: (conteo / total_frames) * 100 for emocion, conteo in emociones.items()}\n",
        "\n",
        "    # Mostrar resultados\n",
        "    print(\"\\nResultados del análisis:\")\n",
        "    print(f\"Nombre: {nombre}, Edad: {edad}, Género: {genero}\")\n",
        "    print(f\"Fecha del análisis: {date.today()}\")\n",
        "    for emocion, porcentaje in porcentajes.items():\n",
        "        print(f\"{emocion}: {porcentaje:.2f}%\")\n",
        "\n",
        "    # Verificar si la suma de porcentajes es 100\n",
        "    suma_porcentajes = sum(porcentajes.values())\n",
        "    print(f\"Suma total: {suma_porcentajes:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9MpjO-7r19t",
        "outputId": "fe106451-0100-4843-833a-d4badb9e724e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Introduce tu nombre: svvd\n",
            "Introduce tu edad: 24\n",
            "Introduce tu género (Hombre/Mujer): avvev\n",
            "Error al abrir el video\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando video: 0it [00:00, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from deepface import DeepFace\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "from datetime import date\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del archivo de video (asegúrate de que la ruta sea correcta)\n",
        "# This is likely the problem. Make sure the path is correct and the file exists\n",
        "video_path = \"carmen1.mp4\"\n",
        "\n",
        "# Pedir nombre, edad y género al inicio\n",
        "nombre = input(\"Introduce tu nombre: \")\n",
        "edad = input(\"Introduce tu edad: \")\n",
        "genero = input(\"Introduce tu género (Hombre/Mujer): \")\n",
        "\n",
        "# Inicializar detección de rostros\n",
        "mp_face_detection = mp.solutions.face_detection\n",
        "face_detection = mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5)\n",
        "\n",
        "# Inicializar diccionario para almacenar emociones\n",
        "emociones = {\n",
        "    'angry': 0,\n",
        "    'disgust': 0,\n",
        "    'fear': 0,\n",
        "    'happy': 0,\n",
        "    'sad': 0,\n",
        "    'surprise': 0,\n",
        "    'neutral': 0\n",
        "}\n",
        "\n",
        "total_frames = 0\n",
        "\n",
        "# Captura de video\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Check if the file was opened correctly\n",
        "if not cap.isOpened():\n",
        "    print(\"Error al abrir el video. Check the file path and try again.\")\n",
        "    exit()\n",
        "\n",
        "# Obtener el número total de frames\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# Iniciar procesamiento de video con barra de progreso\n",
        "with tqdm(total=total_frames, desc=\"Procesando video\") as pbar:\n",
        "    while(True):\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Convertir a RGB\n",
        "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Detectar rostros\n",
        "        results = face_detection.process(rgb)\n",
        "\n",
        "        if results.detections:\n",
        "            for detection in results.detections:\n",
        "                try:\n",
        "                    # Analizar emociones\n",
        "                    analyze = DeepFace.analyze(rgb, actions=['emotion'], enforce_detection=False)\n",
        "\n",
        "                    # Manejar el caso en que `DeepFace.analyze` devuelve una lista\n",
        "                    if isinstance(analyze, list):\n",
        "                        analyze = analyze[0]\n",
        "\n",
        "                    # Contar emociones\n",
        "                    emocion = analyze['dominant_emotion']\n",
        "                    emociones[emocion] += 1\n",
        "                except Exception as e:\n",
        "                    print(f\"Error al analizar el rostro: {e}\")\n",
        "\n",
        "        pbar.update(1)\n",
        "\n",
        "# Liberar recursos\n",
        "cap.release()\n",
        "\n",
        "# Calcular porcentajes\n",
        "if total_frames > 0:\n",
        "    porcentajes = {emocion: (conteo / total_frames) * 100 for emocion, conteo in emociones.items()}\n",
        "\n",
        "    # Mostrar resultados\n",
        "    print(\"\\nResultados del análisis:\")\n",
        "    print(f\"Nombre: {nombre}, Edad: {edad}, Género: {genero}\")\n",
        "    print(f\"Fecha del análisis: {date.today()}\")\n",
        "    for emocion, porcentaje in porcentajes.items():\n",
        "        print(f\"{emocion}: {porcentaje:.2f}%\")\n",
        "\n",
        "    # Verificar si la suma de porcentajes es 100\n",
        "    suma_porcentajes = sum(porcentajes.values())\n",
        "    print(f\"Suma total: {suma_porcentajes:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFejE8Kx7SSm",
        "outputId": "9d3e1c5b-1356-4c12-8050-904c7c55cc0e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Introduce tu nombre: dnjrd\n",
            "Introduce tu edad: 25\n",
            "Introduce tu género (Hombre/Mujer): gjffk\n",
            "Error al abrir el video. Check the file path and try again.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando video: 0it [00:00, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "!source my_env/bin/activate; pip install mediapipe\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kFp74t6qNoF",
        "outputId": "fb1b9fed-33fa-48ed-8117-a8dbc0ab858c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Using cached mediapipe-0.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Collecting absl-py (from mediapipe)\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting attrs>=19.1.0 (from mediapipe)\n",
            "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting flatbuffers>=2.0 (from mediapipe)\n",
            "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
            "Collecting jax (from mediapipe)\n",
            "  Using cached jax-0.4.33-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib (from mediapipe)\n",
            "  Using cached jaxlib-0.4.33-cp310-cp310-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting matplotlib (from mediapipe)\n",
            "  Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting numpy<2 (from mediapipe)\n",
            "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting opencv-contrib-python (from mediapipe)\n",
            "  Using cached opencv_contrib_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
            "  Using cached protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Using cached sounddevice-0.5.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting CFFI>=1.0 (from sounddevice>=0.4.4->mediapipe)\n",
            "  Using cached cffi-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting ml-dtypes>=0.2.0 (from jax->mediapipe)\n",
            "  Downloading ml_dtypes-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Collecting opt-einsum (from jax->mediapipe)\n",
            "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting scipy>=1.10 (from jax->mediapipe)\n",
            "  Downloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib->mediapipe)\n",
            "  Using cached contourpy-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib->mediapipe)\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib->mediapipe)\n",
            "  Using cached fonttools-4.54.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (163 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib->mediapipe)\n",
            "  Using cached kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
            "Collecting packaging>=20.0 (from matplotlib->mediapipe)\n",
            "  Using cached packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pillow>=8 (from matplotlib->mediapipe)\n",
            "  Using cached pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib->mediapipe)\n",
            "  Using cached pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting python-dateutil>=2.7 (from matplotlib->mediapipe)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pycparser (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe)\n",
            "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib->mediapipe)\n",
            "  Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Using cached mediapipe-0.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.9 MB)\n",
            "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
            "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
            "Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "Using cached protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "Using cached sounddevice-0.5.0-py3-none-any.whl (32 kB)\n",
            "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "Using cached jax-0.4.33-py3-none-any.whl (2.1 MB)\n",
            "Using cached jaxlib-0.4.33-cp310-cp310-manylinux2014_x86_64.whl (85.0 MB)\n",
            "Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached opencv_contrib_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (68.7 MB)\n",
            "Using cached cffi-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (446 kB)\n",
            "Using cached contourpy-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (322 kB)\n",
            "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Using cached fonttools-4.54.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "Using cached kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "Downloading ml_dtypes-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached packaging-24.1-py3-none-any.whl (53 kB)\n",
            "Using cached pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "Using cached pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
            "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Downloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
            "Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
            "Installing collected packages: flatbuffers, six, pyparsing, pycparser, protobuf, pillow, packaging, opt-einsum, numpy, kiwisolver, fonttools, cycler, attrs, absl-py, scipy, python-dateutil, opencv-contrib-python, ml-dtypes, contourpy, CFFI, sounddevice, matplotlib, jaxlib, jax, mediapipe\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.1.1\n",
            "    Uninstalling numpy-2.1.1:\n",
            "      Successfully uninstalled numpy-2.1.1\n",
            "Successfully installed CFFI-1.17.1 absl-py-2.1.0 attrs-24.2.0 contourpy-1.3.0 cycler-0.12.1 flatbuffers-24.3.25 fonttools-4.54.1 jax-0.4.33 jaxlib-0.4.33 kiwisolver-1.4.7 matplotlib-3.9.2 mediapipe-0.10.15 ml-dtypes-0.5.0 numpy-1.26.4 opencv-contrib-python-4.10.0.84 opt-einsum-3.4.0 packaging-24.1 pillow-10.4.0 protobuf-4.25.5 pycparser-2.22 pyparsing-3.1.4 python-dateutil-2.9.0.post0 scipy-1.14.1 six-1.16.0 sounddevice-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GPqBS5Dct9VU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OJEzBDRtdo5"
      },
      "source": [
        "For example, here we download and display a PNG image of the Colab logo:"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOK0lnTLdCoO+bLZX8Xah2K",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}